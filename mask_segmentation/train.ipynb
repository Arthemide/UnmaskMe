{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## setup de l'environement","metadata":{"id":"iLpnCK-PL64w"}},{"cell_type":"code","source":"import splitfolders  # or import split_folders\n\nsplitfolders.ratio(\"../../input/celeba-dataset/img_align_celeba\", output=\"output\", seed=1337, ratio=(.6, .2, .2), group_prefix=None) # default values\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:56:16.257237Z","iopub.execute_input":"2021-11-29T09:56:16.257789Z","iopub.status.idle":"2021-11-29T09:56:59.509396Z","shell.execute_reply.started":"2021-11-29T09:56:16.25775Z","shell.execute_reply":"2021-11-29T09:56:59.508323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/aqeelanwar/MaskTheFace.git","metadata":{"execution":{"iopub.status.busy":"2021-11-30T13:30:11.920796Z","iopub.execute_input":"2021-11-30T13:30:11.921098Z","iopub.status.idle":"2021-11-30T13:30:22.81209Z","shell.execute_reply.started":"2021-11-30T13:30:11.921011Z","shell.execute_reply":"2021-11-30T13:30:22.811293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install dotmap imutils split-folders","metadata":{"execution":{"iopub.status.busy":"2021-11-30T13:30:22.813822Z","iopub.execute_input":"2021-11-30T13:30:22.814108Z","iopub.status.idle":"2021-11-30T13:30:29.979496Z","shell.execute_reply.started":"2021-11-30T13:30:22.814055Z","shell.execute_reply":"2021-11-30T13:30:29.978662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i 's/ utils./ MaskTheFace.utils./' /kaggle/working/MaskTheFace/utils/aux_functions.py","metadata":{"execution":{"iopub.status.busy":"2021-11-30T13:30:29.982934Z","iopub.execute_input":"2021-11-30T13:30:29.98319Z","iopub.status.idle":"2021-11-30T13:30:30.640963Z","shell.execute_reply.started":"2021-11-30T13:30:29.983162Z","shell.execute_reply":"2021-11-30T13:30:30.640127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('./MaskTheFace')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T13:32:12.156955Z","iopub.execute_input":"2021-11-30T13:32:12.157549Z","iopub.status.idle":"2021-11-30T13:32:12.173383Z","shell.execute_reply.started":"2021-11-30T13:32:12.157509Z","shell.execute_reply":"2021-11-30T13:32:12.172434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport torch.nn.functional as F\nfrom torchvision.transforms import ToTensor, Lambda, Compose\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nfrom tqdm.auto import tqdm as tq\nfrom PIL import Image","metadata":{"id":"Uy3shNC7yqKf","execution":{"iopub.status.busy":"2021-11-30T13:30:30.649937Z","iopub.execute_input":"2021-11-30T13:30:30.650473Z","iopub.status.idle":"2021-11-30T13:30:32.162216Z","shell.execute_reply.started":"2021-11-30T13:30:30.650439Z","shell.execute_reply":"2021-11-30T13:30:32.161386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model - Unet","metadata":{"id":"BoemUMevMHce"}},{"cell_type":"code","source":"class double_conv(nn.Module):\n    \"\"\"(conv => BN => ReLU) * 2\"\"\"\n\n    def __init__(self, in_ch, out_ch):\n        super(double_conv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass inconv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(inconv, self).__init__()\n        self.conv = double_conv(in_ch, out_ch)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass down(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(down, self).__init__()\n        self.mpconv = nn.Sequential(nn.MaxPool2d(2), double_conv(in_ch, out_ch))\n\n    def forward(self, x):\n        x = self.mpconv(x)\n        return x\n\n\nclass up(nn.Module):\n    def __init__(self, in_ch, out_ch, bilinear=True):\n        super(up, self).__init__()\n\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode=\"nearest\", align_corners=True)\n        else:\n            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n\n        self.conv = double_conv(in_ch, out_ch)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n        \n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass outconv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(outconv, self).__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes):\n        super(UNet, self).__init__()\n        self.inc = inconv(n_channels, 64)\n        self.down1 = down(64, 128)\n        self.down2 = down(128, 256)\n        self.down3 = down(256, 512)\n        self.down4 = down(512, 512)\n        self.up1 = up(1024, 256, False)\n        self.up2 = up(512, 128, False)\n        self.up3 = up(256, 64, False)\n        self.up4 = up(128, 64, False)\n        self.outc = outconv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        x = self.outc(x)\n        return torch.sigmoid(x)","metadata":{"id":"HA1SVflgyvsj","execution":{"iopub.status.busy":"2021-11-30T13:30:32.163755Z","iopub.execute_input":"2021-11-30T13:30:32.164Z","iopub.status.idle":"2021-11-30T13:30:32.185882Z","shell.execute_reply.started":"2021-11-30T13:30:32.163966Z","shell.execute_reply":"2021-11-30T13:30:32.184985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD = False\nPATH = '../model.pth'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(3,1).float()\nif LOAD :\n    model.load_state_dict(torch.load(PATH,map_location=device))\n\nmodel.to(device)","metadata":{"id":"8Acnfjqgytut","execution":{"iopub.status.busy":"2021-11-30T13:30:32.187533Z","iopub.execute_input":"2021-11-30T13:30:32.188039Z","iopub.status.idle":"2021-11-30T13:30:35.214536Z","shell.execute_reply.started":"2021-11-30T13:30:32.188003Z","shell.execute_reply":"2021-11-30T13:30:35.213674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## data loader","metadata":{"id":"d1f94B1FMO-6"}},{"cell_type":"code","source":"#@title Default title text\nimport torch\nfrom skimage.io import imread\nfrom torch.utils import data\nimport os\nfrom MaskTheFace.utils.aux_functions import mask_image , download_dlib_model\nimport argparse\nimport dlib\nimport torchvision.transforms.functional as TF\nimport random\nfrom torchvision import datasets, transforms\n\n\nclass AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\nclass Args():\n    def __init__(self,mask_types=['surgical'],pattern='',color='#0473e2',color_weight = 0.5):\n        self.mask_types = mask_types\n        self.mask_type = mask_types[0] #'surgical', 'N95', 'KN95', 'cloth', 'gas'\n        self.pattern = pattern\n        self.color = color\n        self.color_weight = color_weight\n    verbose = False\n    code = None\n    path_to_dlib_model = \"dlib_models/shape_predictor_68_face_landmarks.dat\"\n    if not os.path.exists(path_to_dlib_model):\n        download_dlib_model()\n    predictor = dlib.shape_predictor(path_to_dlib_model)\n    detector = dlib.get_frontal_face_detector()\n\nclass dataset(data.Dataset):\n    def __init__(self,src_image,args,train='train'):   # initial logic happens like transform\n        self.src_image = src_image\n        self.image_paths = os.listdir(src_image)\n        self.args = args\n        self.train = train\n        print('number of images:',self.__len__())\n        \n    def transform(self, image, mask):\n        image = image[:, :, ::-1]\n        topil = transforms.ToPILImage()\n        image , mask = topil(image), topil(mask)\n        \n        resize = transforms.Resize(size=(128,128))\n        image, mask = resize(image), resize(mask)\n\n        if random.random() > 0.5:\n            image, mask= TF.hflip(image), TF.hflip(mask)\n\n        # Transform to tensor\n        image, mask = TF.to_tensor(image), TF.to_tensor(mask)\n        return image, mask\n        \n        \n    def __getitem__(self, index):\n        if self.train == 'validation' :\n            index += int(len(self.image_paths) * 0.6)\n        elif self.train == 'test' :\n            index += int(len(self.image_paths) * 0.8)\n        src = os.path.join(self.src_image,self.image_paths[index])\n        args.mask_type = random.choice(self.args.mask_types)\n        masked,masktype,mask,original = mask_image(src,self.args)\n        if len(masked) == 0 or len(mask) == 0 :\n            return None\n        image, mask = self.transform(masked[0], mask[0])\n        return image, mask\n\n    def __len__(self):  # return count of sample we have\n        if self.train == 'train':\n            return int(len(self.image_paths) * 0.6) \n        return int(len(self.image_paths) * 0.2)\n               ","metadata":{"cellView":"code","id":"qbeW5CARyvmq","execution":{"iopub.status.busy":"2021-11-30T13:30:35.216137Z","iopub.execute_input":"2021-11-30T13:30:35.216416Z","iopub.status.idle":"2021-11-30T13:30:46.75952Z","shell.execute_reply.started":"2021-11-30T13:30:35.21638Z","shell.execute_reply":"2021-11-30T13:30:46.75873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_collate(batch):\n    len_batch = len(batch) # original batch length\n    batch = list(filter (lambda x:x is not None, batch)) # filter out all the Nones\n    if len_batch > len(batch): # if there are samples missing just use existing members, doesn't work if you reject every sample in a batch\n        diff = len_batch - len(batch)\n        for i in range(diff):\n            batch = batch + batch[:diff]\n    return torch.utils.data.dataloader.default_collate(batch)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T13:30:46.762392Z","iopub.execute_input":"2021-11-30T13:30:46.762738Z","iopub.status.idle":"2021-11-30T13:30:46.767875Z","shell.execute_reply.started":"2021-11-30T13:30:46.762699Z","shell.execute_reply":"2021-11-30T13:30:46.76705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input","metadata":{"execution":{"iopub.status.busy":"2021-11-30T13:33:45.495797Z","iopub.execute_input":"2021-11-30T13:33:45.496094Z","iopub.status.idle":"2021-11-30T13:33:46.182638Z","shell.execute_reply.started":"2021-11-30T13:33:45.496048Z","shell.execute_reply":"2021-11-30T13:33:46.181819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = Args()\n\ntrain_dataset = dataset('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba',args,'train')\nval_dataset   = dataset('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba',args,'validation')\nbatch_size = 8\nnum_workers = 2\ntrainloader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,collate_fn = my_collate\n)\nvalloader = DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,collate_fn = my_collate\n)","metadata":{"id":"qGmzKc7tyvey","outputId":"12780d41-2256-4c45-ded4-0677a08220d5","execution":{"iopub.status.busy":"2021-11-30T13:34:13.940057Z","iopub.execute_input":"2021-11-30T13:34:13.940718Z","iopub.status.idle":"2021-11-30T13:34:16.832861Z","shell.execute_reply.started":"2021-11-30T13:34:13.940673Z","shell.execute_reply":"2021-11-30T13:34:16.831994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y = train_dataset.__getitem__(0)\nprint(x.shape,y.shape)\nx,y = val_dataset.__getitem__(0)\nprint(x.shape,y.shape)\ny.mean()","metadata":{"id":"9Wu9ftswyvTs","outputId":"2fc88429-1085-4c98-cdb6-4c87792c19c7","execution":{"iopub.status.busy":"2021-11-29T08:44:57.146474Z","iopub.execute_input":"2021-11-29T08:44:57.147979Z","iopub.status.idle":"2021-11-29T08:44:57.303712Z","shell.execute_reply.started":"2021-11-29T08:44:57.147905Z","shell.execute_reply":"2021-11-29T08:44:57.302871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training ","metadata":{"id":"9WVb1KfGMqO6"}},{"cell_type":"code","source":"def dice_coef_metric(pred, label):\n    intersection = 2.0 * (pred * label).sum()\n    union = pred.sum() + label.sum()\n    if pred.sum() == 0 and label.sum() == 0:\n        return 1.\n    return intersection / union\ndef dice_coef_loss(pred, label):\n    smooth = 1.0\n    intersection = 2.0 * (pred * label).sum() + smooth\n    union = pred.sum() + label.sum() + smooth\n    return 1 - (intersection / union)\ndef bce_dice_loss(pred, label):\n    dice_loss = dice_coef_loss(pred, label)\n    bce_loss = nn.BCELoss()(pred, label)\n    return dice_loss + bce_loss\ndef compute_iou(model, loader, threshold=0.3):\n    valloss = 0\n    with torch.no_grad():\n        for step, (data, target) in enumerate(loader):\n            data = data.to(device)\n            target = target.to(device)\n\n            outputs = model(data)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n\n            loss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            valloss += loss\n\n    return valloss / step","metadata":{"id":"2HFW5kN6fZzz","execution":{"iopub.status.busy":"2021-11-30T13:34:23.273766Z","iopub.execute_input":"2021-11-30T13:34:23.27404Z","iopub.status.idle":"2021-11-30T13:34:23.291269Z","shell.execute_reply.started":"2021-11-30T13:34:23.274011Z","shell.execute_reply":"2021-11-30T13:34:23.289799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n    \n    loss_history = []\n    train_history = []\n    val_history = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        \n        losses = []\n        train_iou = []\n        \n        for i, (image, mask) in enumerate(tqdm(train_loader)):\n            image = image.to(device)\n            mask = mask.to(device)\n            outputs = model(image)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n            \n            train_dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n            loss = loss_func(outputs, mask)\n            losses.append(loss.item())\n            train_iou.append(train_dice)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n                \n        val_mean_iou = compute_iou(model, val_loader)\n        scheduler.step(val_mean_iou)\n        loss_history.append(np.array(losses).mean())\n        train_history.append(np.array(train_iou).mean())\n        val_history.append(val_mean_iou)\n        \n        print('Epoch : {}/{}'.format(epoch+1, num_epochs))\n        print('loss: {:.3f} - dice_coef: {:.3f} - val_dice_coef: {:.3f}'.format(np.array(losses).mean(),\n                                                                               np.array(train_iou).mean()\n                                                                               ,val_mean_iou))\n    return loss_history, train_history, val_history\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n","metadata":{"id":"9mbc5LAKfHgl","execution":{"iopub.status.busy":"2021-11-30T13:34:24.133253Z","iopub.execute_input":"2021-11-30T13:34:24.13387Z","iopub.status.idle":"2021-11-30T13:34:24.146776Z","shell.execute_reply.started":"2021-11-30T13:34:24.133828Z","shell.execute_reply":"2021-11-30T13:34:24.145981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_list, valid_loss_list, dice_score_list = train_model(trainloader,valloader,bce_dice_loss,optimizer,scheduler,3)\n#torch.save(model.state_dict(), './path')","metadata":{"id":"HfgP5QDtz03j","outputId":"0115c669-eb6a-4188-9899-6898fe35d781","execution":{"iopub.status.busy":"2021-11-30T13:34:25.690154Z","iopub.execute_input":"2021-11-30T13:34:25.690438Z","iopub.status.idle":"2021-11-30T20:49:28.882137Z","shell.execute_reply.started":"2021-11-30T13:34:25.690408Z","shell.execute_reply":"2021-11-30T20:49:28.880498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:49:29.144506Z","iopub.execute_input":"2021-11-30T20:49:29.144744Z","iopub.status.idle":"2021-11-30T20:49:29.295108Z","shell.execute_reply.started":"2021-11-30T20:49:29.144716Z","shell.execute_reply":"2021-11-30T20:49:29.294226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ploting training ","metadata":{"id":"aeothuppM0pU"}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\nplt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\nplt.ylabel('loss', fontsize=22)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-11-11T03:37:04.660266Z","iopub.status.busy":"2021-11-11T03:37:04.659476Z","iopub.status.idle":"2021-11-11T03:37:05.140006Z","shell.execute_reply":"2021-11-11T03:37:05.138797Z","shell.execute_reply.started":"2021-11-11T03:37:04.660234Z"},"id":"kG_ATKrVZp8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(h.history['loss']);\nplt.plot(h.history['val_loss']);\nplt.title(\"SEG Model focal tversky Loss\");\nplt.ylabel(\"focal tversky loss\");\nplt.xlabel(\"Epochs\");\nplt.legend(['train', 'val']);\n\nplt.subplot(1,2,2)\nplt.plot(h.history['tversky']);\nplt.plot(h.history['val_tversky']);\nplt.title(\"SEG Model tversky score\");\nplt.ylabel(\"tversky Accuracy\");\nplt.xlabel(\"Epochs\");\nplt.legend(['train', 'val']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fast_display(*img2dlist):\n    plt.figure(figsize=(16,8))\n    nbimg = len(img2dlist)\n    cols = min (9,nbimg)\n    rows = (nbimg // cols) +1\n    for ii, img2d in enumerate(img2dlist):\n        plt.subplot(rows,cols,1+ii)\n        plt.imshow(img2d)\n    plt.show()\n   ","metadata":{"id":"YaLyiQqu_vna","execution":{"iopub.status.busy":"2021-11-30T13:09:22.150329Z","iopub.execute_input":"2021-11-30T13:09:22.150619Z","iopub.status.idle":"2021-11-30T13:09:22.156214Z","shell.execute_reply.started":"2021-11-30T13:09:22.150586Z","shell.execute_reply":"2021-11-30T13:09:22.155537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{"id":"sONgY_eXNPXz"}},{"cell_type":"code","source":"x,y = train_dataset.__getitem__(0)\nfor i, (data, target) in enumerate(trainloader):\n    if True:\n        data = data.cuda()\n    output = ((model(data))[0]).cpu().detach().numpy()\n    if i == 3:\n        break\nx = data.cpu().detach().numpy() \ny = target.cpu().detach().numpy() \n#x = np.moveaxis(x, 0, 2)\nprint(x.shape ,x.dtype)\nprint(y.shape ,y.dtype)\nprint(output.shape ,output.dtype)\nfast_display(x[0][0] ,y[0][0],output[0] )","metadata":{"id":"FKWSZ9eWz1aa","outputId":"2b341ab4-e959-47c7-fd83-c2ba6add2417","execution":{"iopub.status.busy":"2021-11-30T13:09:27.314648Z","iopub.execute_input":"2021-11-30T13:09:27.315598Z","iopub.status.idle":"2021-11-30T13:09:30.320315Z","shell.execute_reply.started":"2021-11-30T13:09:27.3155Z","shell.execute_reply":"2021-11-30T13:09:30.319541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.moveaxis(x[0], 0, 2)\nprint(x.shape ,x.dtype)\nprint(y.shape ,y.dtype)\nprint(output.shape ,output.dtype)\nfast_display(x ,y[0][0],output[0] )\n","metadata":{"id":"vLRT3ms4z1Q3","outputId":"1a8908ae-7877-41ec-f1c0-29a10d17cf3a","execution":{"iopub.status.busy":"2021-11-29T09:53:19.239674Z","iopub.execute_input":"2021-11-29T09:53:19.239953Z","iopub.status.idle":"2021-11-29T09:53:19.859521Z","shell.execute_reply.started":"2021-11-29T09:53:19.239923Z","shell.execute_reply":"2021-11-29T09:53:19.858816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\n\nurl = 'https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.federationdesdiabetiques.org%2Ffederation%2Factualites%2Fcoronavirus-covid-19-les-masques-et-les-gants-pour-qui-et-quand-les-porter&psig=AOvVaw0HF-UZhAecG_nUcRVzB4UB&ust=1638364198971000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCKC7gLWUwPQCFQAAAAAdAAAAABAD'\n#img = Image.open(requests.get(url, stream=True).raw)\nrequests.get(url, stream=True).raw","metadata":{"id":"IWBfRLh54X78","execution":{"iopub.status.busy":"2021-11-30T13:17:45.972246Z","iopub.execute_input":"2021-11-30T13:17:45.972799Z","iopub.status.idle":"2021-11-30T13:17:46.08672Z","shell.execute_reply.started":"2021-11-30T13:17:45.972762Z","shell.execute_reply":"2021-11-30T13:17:46.085923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fast_display(img)","metadata":{"cellView":"code","id":"qbeW5CARyvmq","execution":{"iopub.status.busy":"2021-11-30T13:12:00.001617Z","iopub.execute_input":"2021-11-30T13:12:00.002347Z","iopub.status.idle":"2021-11-30T13:12:00.017875Z","shell.execute_reply.started":"2021-11-30T13:12:00.002302Z","shell.execute_reply":"2021-11-30T13:12:00.016567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntraindataset = dataset('','../data/img_align_celeba',args)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y = traindataset.__getitem__(101)\nfast_display(x[0],y[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:51:42.741639Z","iopub.execute_input":"2021-11-29T09:51:42.742026Z","iopub.status.idle":"2021-11-29T09:51:42.781443Z","shell.execute_reply.started":"2021-11-29T09:51:42.741983Z","shell.execute_reply":"2021-11-29T09:51:42.779261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}